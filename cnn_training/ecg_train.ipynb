{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfb97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 1796\n",
      "Unique classes (persons): 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "1  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "2  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "3  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "4  C:/Users/manog/Downloads/ecg_augmented\\person_...      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to augmented dataset folder\n",
    "data_dir = r\"C:/Users/manog/Downloads/ecg_augmented\"\n",
    "\n",
    "# Prepare lists for filenames and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each person's folder\n",
    "for person_folder in sorted(os.listdir(data_dir)):\n",
    "    person_path = os.path.join(data_dir, person_folder)\n",
    "    if os.path.isdir(person_path):\n",
    "        label = int(person_folder.split('_')[1])  # Extract person number from folder name 'person_0' -> 0\n",
    "        for img_file in os.listdir(person_path):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                filepaths.append(os.path.join(person_path, img_file))\n",
    "                labels.append(label)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'filename': filepaths,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Unique classes (persons): {df['label'].nunique()}\")\n",
    "\n",
    "# Show first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50df1edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder: person_0\n",
      "Found folder: person_1\n",
      "Found folder: person_10\n",
      "Found folder: person_11\n",
      "Found folder: person_12\n",
      "Found folder: person_13\n",
      "Found folder: person_14\n",
      "Found folder: person_15\n",
      "Found folder: person_16\n",
      "Found folder: person_17\n",
      "Found folder: person_18\n",
      "Found folder: person_19\n",
      "Found folder: person_2\n",
      "Found folder: person_20\n",
      "Found folder: person_21\n",
      "Found folder: person_22\n",
      "Found folder: person_23\n",
      "Found folder: person_24\n",
      "Found folder: person_25\n",
      "Found folder: person_26\n",
      "Found folder: person_27\n",
      "Found folder: person_28\n",
      "Found folder: person_29\n",
      "Found folder: person_3\n",
      "Found folder: person_30\n",
      "Found folder: person_31\n",
      "Found folder: person_32\n",
      "Found folder: person_33\n",
      "Found folder: person_34\n",
      "Found folder: person_35\n",
      "Found folder: person_36\n",
      "Found folder: person_37\n",
      "Found folder: person_38\n",
      "Found folder: person_39\n",
      "Found folder: person_4\n",
      "Found folder: person_40\n",
      "Found folder: person_41\n",
      "Found folder: person_42\n",
      "Found folder: person_43\n",
      "Found folder: person_44\n",
      "Found folder: person_45\n",
      "Found folder: person_46\n",
      "Found folder: person_47\n",
      "Found folder: person_48\n",
      "Found folder: person_49\n",
      "Found folder: person_5\n",
      "Found folder: person_50\n",
      "Found folder: person_51\n",
      "Found folder: person_52\n",
      "Found folder: person_53\n",
      "Found folder: person_54\n",
      "Found folder: person_55\n",
      "Found folder: person_56\n",
      "Found folder: person_57\n",
      "Found folder: person_58\n",
      "Found folder: person_59\n",
      "Found folder: person_6\n",
      "Found folder: person_60\n",
      "Found folder: person_61\n",
      "Found folder: person_62\n",
      "Found folder: person_63\n",
      "Found folder: person_64\n",
      "Found folder: person_65\n",
      "Found folder: person_66\n",
      "Found folder: person_67\n",
      "Found folder: person_68\n",
      "Found folder: person_69\n",
      "Found folder: person_7\n",
      "Found folder: person_70\n",
      "Found folder: person_71\n",
      "Found folder: person_72\n",
      "Found folder: person_73\n",
      "Found folder: person_74\n",
      "Found folder: person_75\n",
      "Found folder: person_76\n",
      "Found folder: person_77\n",
      "Found folder: person_78\n",
      "Found folder: person_79\n",
      "Found folder: person_8\n",
      "Found folder: person_80\n",
      "Found folder: person_81\n",
      "Found folder: person_82\n",
      "Found folder: person_83\n",
      "Found folder: person_84\n",
      "Found folder: person_85\n",
      "Found folder: person_86\n",
      "Found folder: person_87\n",
      "Found folder: person_88\n",
      "Found folder: person_89\n",
      "Found folder: person_9\n",
      "Total images: 1796\n",
      "Unique classes (persons): 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/manog/Downloads/ecg_augmented\\person_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "1  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "2  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "3  C:/Users/manog/Downloads/ecg_augmented\\person_...      0\n",
       "4  C:/Users/manog/Downloads/ecg_augmented\\person_...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = r\"C:/Users/manog/Downloads/ecg_augmented\"\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for person_folder in sorted(os.listdir(data_dir)):\n",
    "    print(\"Found folder:\", person_folder)  # Debug print to check folder names\n",
    "    person_path = os.path.join(data_dir, person_folder)\n",
    "    if os.path.isdir(person_path):\n",
    "        # Try to parse the person number from the folder name\n",
    "        # Assuming folder names are like 'person_0', 'person_1', ...\n",
    "        try:\n",
    "            label = int(person_folder.split('_')[1])\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing label from folder '{person_folder}': {e}\")\n",
    "            continue\n",
    "        for img_file in os.listdir(person_path):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                filepaths.append(os.path.join(person_path, img_file))\n",
    "                labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filepaths,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Unique classes (persons): {df['label'].nunique()}\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2aafe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 3600\n",
      "Sample pair and label: ['C:/Users/manog/Downloads/ecg_augmented\\\\person_0\\\\person_0_aug_0_4413.png'\n",
      " 'C:/Users/manog/Downloads/ecg_augmented\\\\person_0\\\\person_0_aug_0_8881.png'], Label: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def create_pairs(df, num_pairs_per_class=20):\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "\n",
    "    # Group images by label for easy access\n",
    "    grouped = df.groupby('label')\n",
    "\n",
    "    labels = df['label'].unique()\n",
    "\n",
    "    for label in labels:\n",
    "        imgs = grouped.get_group(label)['filename'].values\n",
    "\n",
    "        # Positive pairs\n",
    "        for _ in range(num_pairs_per_class):\n",
    "            i1, i2 = np.random.choice(len(imgs), 2, replace=False)\n",
    "            pairs.append([imgs[i1], imgs[i2]])\n",
    "            pair_labels.append(1)\n",
    "\n",
    "        # Negative pairs\n",
    "        for _ in range(num_pairs_per_class):\n",
    "            neg_label = np.random.choice(labels[labels != label])\n",
    "            neg_imgs = grouped.get_group(neg_label)['filename'].values\n",
    "            i1 = np.random.choice(len(imgs))\n",
    "            i2 = np.random.choice(len(neg_imgs))\n",
    "            pairs.append([imgs[i1], neg_imgs[i2]])\n",
    "            pair_labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(pair_labels)\n",
    "\n",
    "pairs, pair_labels = create_pairs(df, num_pairs_per_class=20)\n",
    "\n",
    "print(f\"Total pairs: {len(pairs)}\")\n",
    "print(f\"Sample pair and label: {pairs[0]}, Label: {pair_labels[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abc2fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 batch shape: (32, 224, 224, 3)\n",
      "Image 2 batch shape: (32, 224, 224, 3)\n",
      "Label batch shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)  # Resize images to this size\n",
    "\n",
    "def preprocess_image(file_path):\n",
    "    # Read the image from disk\n",
    "    img = tf.io.read_file(file_path)\n",
    "    # Decode PNG or JPG as needed\n",
    "    img = tf.image.decode_png(img, channels=3)  # or decode_jpeg if jpeg images\n",
    "    # Resize to IMG_SIZE\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_pair(file_path_1, file_path_2, label):\n",
    "    img1 = preprocess_image(file_path_1)\n",
    "    img2 = preprocess_image(file_path_2)\n",
    "    return (img1, img2), label\n",
    "\n",
    "# Convert numpy pairs and labels to tf.data Dataset\n",
    "def create_dataset(pairs, labels, batch_size=32, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((pairs[:, 0], pairs[:, 1], labels))\n",
    "    dataset = dataset.map(preprocess_pair, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Create dataset\n",
    "batch_size = 32\n",
    "dataset = create_dataset(pairs, pair_labels, batch_size=batch_size)\n",
    "\n",
    "# Preview dataset batch shapes\n",
    "for (img1, img2), label in dataset.take(1):\n",
    "    print(f\"Image 1 batch shape: {img1.shape}\")\n",
    "    print(f\"Image 2 batch shape: {img2.shape}\")\n",
    "    print(f\"Label batch shape: {label.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a0b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\manog\\Downloads\\biometric_attendance_system\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siamese_network\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"siamese_network\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">542,464</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m542,464\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,593</span> (2.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m542,593\u001b[0m (2.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,593</span> (2.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m542,593\u001b[0m (2.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model, Input\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def build_embedding_model(input_shape=(224, 224, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (7,7), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(128, (5,5), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)  # Embedding vector size 128\n",
    "    model = Model(inputs, x, name=\"embedding\")\n",
    "    return model\n",
    "\n",
    "def build_siamese_network(input_shape=(224,224,3)):\n",
    "    # Inputs for two images\n",
    "    input_1 = Input(shape=input_shape)\n",
    "    input_2 = Input(shape=input_shape)\n",
    "    \n",
    "    embedding_model = build_embedding_model(input_shape)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    emb1 = embedding_model(input_1)\n",
    "    emb2 = embedding_model(input_2)\n",
    "    \n",
    "    # Compute L1 distance between embeddings\n",
    "    l1_distance = layers.Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([emb1, emb2])\n",
    "    \n",
    "    # Output layer (sigmoid for similarity probability)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(l1_distance)\n",
    "    \n",
    "    siamese_net = Model(inputs=[input_1, input_2], outputs=outputs, name=\"siamese_network\")\n",
    "    return siamese_net\n",
    "\n",
    "# Build model\n",
    "siamese_model = build_siamese_network()\n",
    "\n",
    "# Compile model with binary crossentropy loss and an optimizer\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "siamese_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64c49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "class SiameseDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size=32, img_size=(224,224), shuffle=True):\n",
    "        \"\"\"\n",
    "        df: DataFrame with columns ['filename', 'label']\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # Group indices by label for quick pair sampling\n",
    "        self.label_to_indices = {}\n",
    "        for label in self.df['label'].unique():\n",
    "            self.label_to_indices[label] = self.df[self.df['label'] == label].index.to_list()\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return len(self.df) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_img1 = []\n",
    "        batch_img2 = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        while len(batch_img1) < self.batch_size:\n",
    "            # Randomly pick first image and its label\n",
    "            idx1 = random.randint(0, len(self.df) - 1)\n",
    "            img1_path = self.df.loc[idx1, 'filename']\n",
    "            label1 = self.df.loc[idx1, 'label']\n",
    "            \n",
    "            # Decide if pair is genuine or impostor (50/50 chance)\n",
    "            if random.random() < 0.5:\n",
    "                # Genuine pair (same label)\n",
    "                idx2 = idx1\n",
    "                while idx2 == idx1:\n",
    "                    idx2 = random.choice(self.label_to_indices[label1])\n",
    "                label = 1\n",
    "            else:\n",
    "                # Impostor pair (different labels)\n",
    "                label = 0\n",
    "                label2 = label1\n",
    "                while label2 == label1:\n",
    "                    label2 = random.choice(list(self.label_to_indices.keys()))\n",
    "                idx2 = random.choice(self.label_to_indices[label2])\n",
    "            \n",
    "            img2_path = self.df.loc[idx2, 'filename']\n",
    "            \n",
    "            # Load images and preprocess\n",
    "            img1 = cv2.imread(img1_path)\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "            img1 = cv2.resize(img1, self.img_size)\n",
    "            img1 = img1 / 255.0\n",
    "            \n",
    "            img2 = cv2.imread(img2_path)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "            img2 = cv2.resize(img2, self.img_size)\n",
    "            img2 = img2 / 255.0\n",
    "            \n",
    "            batch_img1.append(img1)\n",
    "            batch_img2.append(img2)\n",
    "            batch_labels.append(label)\n",
    "        \n",
    "        return [np.array(batch_img1), np.array(batch_img2)], np.array(batch_labels)\n",
    "\n",
    "# Usage:\n",
    "# Assuming 'df' is your DataFrame with 'filename' and 'label' columns from the augmented data\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = SiameseDataGenerator(df, batch_size=batch_size, img_size=(224,224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4003e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ base_encoder        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">542,464</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ base_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ base_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ base_encoder        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m542,464\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ base_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ base_encoder[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,593</span> (2.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m542,593\u001b[0m (2.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,593</span> (2.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m542,593\u001b[0m (2.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "\n",
    "def create_base_encoder(input_shape=(224,224,3), embedding_dim=128):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (7,7), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, (5,5), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(embedding_dim)(x)\n",
    "    x = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)  # Normalize embeddings\n",
    "    return Model(inputs, x, name='base_encoder')\n",
    "\n",
    "# Input pairs\n",
    "input_a = Input(shape=(224,224,3))\n",
    "input_b = Input(shape=(224,224,3))\n",
    "\n",
    "# Shared encoder\n",
    "encoder = create_base_encoder()\n",
    "\n",
    "encoded_a = encoder(input_a)\n",
    "encoded_b = encoder(input_b)\n",
    "\n",
    "# Compute absolute difference between embeddings\n",
    "L1_layer = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([encoded_a, encoded_b])\n",
    "\n",
    "# Final decision layer\n",
    "outputs = layers.Dense(1, activation='sigmoid')(L1_distance)\n",
    "\n",
    "# Define the Siamese network\n",
    "siamese_model = Model(inputs=[input_a, input_b], outputs=outputs)\n",
    "\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "siamese_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdf3208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pairs: 3600, Genuine: 1800, Impostor: 1800\n"
     ]
    }
   ],
   "source": [
    "def create_image_pairs(df, num_pairs_per_person=10):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    grouped = df.groupby('label')\n",
    "\n",
    "    for label, group in grouped:\n",
    "        images = group['filename'].tolist()\n",
    "\n",
    "        # Genuine pairs\n",
    "        if len(images) >= 2:\n",
    "            for _ in range(num_pairs_per_person):\n",
    "                img1, img2 = random.sample(images, 2)\n",
    "                pairs.append((load_and_preprocess_image(img1), load_and_preprocess_image(img2)))\n",
    "                labels.append(1)\n",
    "\n",
    "        # Impostor pairs\n",
    "        other_labels = df['label'].unique().tolist()\n",
    "        other_labels.remove(label)\n",
    "\n",
    "        for _ in range(num_pairs_per_person):\n",
    "            other_label = random.choice(other_labels)\n",
    "            other_img = random.choice(df[df['label'] == other_label]['filename'].tolist())\n",
    "            img1 = random.choice(images)\n",
    "            pairs.append((load_and_preprocess_image(img1), load_and_preprocess_image(other_img)))\n",
    "            labels.append(0)\n",
    "\n",
    "    # Shuffle\n",
    "    pairs, labels = shuffle(pairs, labels, random_state=42)\n",
    "\n",
    "    X1 = np.array([pair[0] for pair in pairs])\n",
    "    X2 = np.array([pair[1] for pair in pairs])\n",
    "    y = np.array(labels)\n",
    "\n",
    "    return X1, X2, y\n",
    "\n",
    "# Create the image pairs\n",
    "X1, X2, y_pairs = create_image_pairs(df, num_pairs_per_person=20)\n",
    "\n",
    "print(f\"Total Pairs: {len(y_pairs)}, Genuine: {sum(y_pairs)}, Impostor: {len(y_pairs) - sum(y_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0c479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def build_embedding_model(input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inp)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f43eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_siamese_model(input_shape):\n",
    "    embedding_model = build_embedding_model(input_shape)\n",
    "\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "\n",
    "    emb_a = embedding_model(input_a)\n",
    "    emb_b = embedding_model(input_b)\n",
    "\n",
    "    # Compute absolute difference\n",
    "    diff = layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([emb_a, emb_b])\n",
    "\n",
    "    x = layers.Dense(64, activation='relu')(diff)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    siamese = Model(inputs=[input_a, input_b], outputs=output)\n",
    "    siamese.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return siamese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f04781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">109,760</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m109,760\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,081</span> (461.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,081\u001b[0m (461.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,081</span> (461.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,081\u001b[0m (461.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "siamese_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0166ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Split the image pairs into training and validation\n",
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = train_test_split(\n",
    "    X1, X2, y_pairs, test_size=0.2, random_state=42, stratify=y_pairs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a9f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class SiamesePairGenerator(Sequence):\n",
    "    def __init__(self, X1_paths, X2_paths, y_labels, batch_size=32, img_size=(224, 224)):\n",
    "        self.X1_paths = X1_paths\n",
    "        self.X2_paths = X2_paths\n",
    "        self.y = y_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x1 = self.X1_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x2 = self.X2_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        X1 = [self._load_image(img) for img in batch_x1]\n",
    "        X2 = [self._load_image(img) for img in batch_x2]\n",
    "\n",
    "        return [np.array(X1), np.array(X2)], np.array(batch_y)\n",
    "\n",
    "    def _load_image(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "793c47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamesePairGenerator(Sequence):\n",
    "    def __init__(self, X1_paths, X2_paths, y_labels, batch_size=32, img_size=(224, 224)):\n",
    "        self.X1_paths = X1_paths\n",
    "        self.X2_paths = X2_paths\n",
    "        self.y = y_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x1 = self.X1_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x2 = self.X2_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        X1 = [self._load_image(img) for img in batch_x1]\n",
    "        X2 = [self._load_image(img) for img in batch_x2]\n",
    "\n",
    "        return [np.array(X1), np.array(X2)], np.array(batch_y)\n",
    "\n",
    "def _load_image(self, path):\n",
    "    print(f\"Loading image from path: {path} (type: {type(path)})\")\n",
    "    path = str(path)\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image at path: {path}\")\n",
    "    img = cv2.resize(img, self.img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab06929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X1_train: <class 'numpy.ndarray'>\n",
      "Type of first element in X1_train: <class 'numpy.ndarray'>\n",
      "Sample from X1_train: [[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "Type of X2_train: <class 'numpy.ndarray'>\n",
      "Type of first element in X2_train: <class 'numpy.ndarray'>\n",
      "Sample from X2_train: [[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n",
      "Sample y_train: [0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Type of X1_train: {type(X1_train)}\")             # Should be numpy.ndarray or list\n",
    "print(f\"Type of first element in X1_train: {type(X1_train[0])}\")  # Should be str or path-like\n",
    "print(f\"Sample from X1_train: {X1_train[0]}\")            # Should print a valid filepath string\n",
    "\n",
    "print(f\"Type of X2_train: {type(X2_train)}\")\n",
    "print(f\"Type of first element in X2_train: {type(X2_train[0])}\")\n",
    "print(f\"Sample from X2_train: {X2_train[0]}\")\n",
    "\n",
    "print(f\"Type of y_train: {type(y_train)}\")\n",
    "print(f\"Sample y_train: {y_train[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fb0af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a dictionary of person -> list of image paths:\n",
    "person_to_images = {\n",
    "    0: ['person_0_img1.png', 'person_0_img2.png', ...],\n",
    "    1: ['person_1_img1.png', 'person_1_img2.png', ...],\n",
    "    # ...\n",
    "}\n",
    "\n",
    "X1_paths = []\n",
    "X2_paths = []\n",
    "y_pairs = []\n",
    "\n",
    "# Generate positive pairs (same person)\n",
    "for person, images in person_to_images.items():\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1, len(images)):\n",
    "            X1_paths.append(images[i])\n",
    "            X2_paths.append(images[j])\n",
    "            y_pairs.append(1)\n",
    "\n",
    "# Generate negative pairs (different persons)\n",
    "persons = list(person_to_images.keys())\n",
    "for i in range(len(persons)):\n",
    "    for j in range(i+1, len(persons)):\n",
    "        imgs1 = person_to_images[persons[i]]\n",
    "        imgs2 = person_to_images[persons[j]]\n",
    "        for img1 in imgs1:\n",
    "            for img2 in imgs2:\n",
    "                X1_paths.append(img1)\n",
    "                X2_paths.append(img2)\n",
    "                y_pairs.append(0)\n",
    "\n",
    "# Convert to numpy array\n",
    "y_pairs = np.array(y_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de3f3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "base_dir = r'C:\\Users\\manog\\Downloads\\ecg_augmented'\n",
    "\n",
    "all_person_folders = [os.path.join(base_dir, f'person_{i}') for i in range(90)]\n",
    "\n",
    "# Collect all image paths by person\n",
    "person_to_images = {}\n",
    "for person_folder in all_person_folders:\n",
    "    images = glob.glob(os.path.join(person_folder, '*.png'))\n",
    "    person_to_images[person_folder] = images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37420d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "X1_paths = []\n",
    "X2_paths = []\n",
    "y_pairs = []\n",
    "\n",
    "# Genuine pairs\n",
    "for person, images in person_to_images.items():\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1, len(images)):\n",
    "            X1_paths.append(images[i])\n",
    "            X2_paths.append(images[j])\n",
    "            y_pairs.append(1)\n",
    "\n",
    "# Impostor pairs\n",
    "persons = list(person_to_images.keys())\n",
    "num_impostor_pairs = len(X1_paths)  # balance number of pairs\n",
    "\n",
    "while len(y_pairs) < 2 * num_impostor_pairs:\n",
    "    p1, p2 = random.sample(persons, 2)\n",
    "    img1 = random.choice(person_to_images[p1])\n",
    "    img2 = random.choice(person_to_images[p2])\n",
    "    X1_paths.append(img1)\n",
    "    X2_paths.append(img2)\n",
    "    y_pairs.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b2be066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_paths = np.array(X1_paths)\n",
    "X2_paths = np.array(X2_paths)\n",
    "y_pairs = np.array(y_pairs)\n",
    "\n",
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = train_test_split(\n",
    "    X1_paths, X2_paths, y_pairs, test_size=0.2, random_state=42, stratify=y_pairs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78cfc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "class SiamesePairGenerator(Sequence):\n",
    "    def __init__(self, X1_paths, X2_paths, y, batch_size=32, img_size=(224, 224), shuffle=True):\n",
    "        self.X1_paths = X1_paths\n",
    "        self.X2_paths = X2_paths\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate batch indexes\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Select data for this batch\n",
    "        batch_X1_paths = self.X1_paths[batch_indexes]\n",
    "        batch_X2_paths = self.X2_paths[batch_indexes]\n",
    "        batch_y = self.y[batch_indexes]\n",
    "\n",
    "        # Load and preprocess images\n",
    "        X1 = np.array([self._load_and_preprocess(img_path) for img_path in batch_X1_paths])\n",
    "        X2 = np.array([self._load_and_preprocess(img_path) for img_path in batch_X2_paths])\n",
    "\n",
    "        return [X1, X2], batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _load_and_preprocess(self, img_path):\n",
    "        # Load image as PIL image\n",
    "        img = load_img(img_path, target_size=self.img_size)\n",
    "        # Convert to numpy array\n",
    "        img_array = img_to_array(img)\n",
    "        # Normalize pixels between 0 and 1\n",
    "        img_array = img_array / 255.0\n",
    "        return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "013a6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = (224, 224)  # or your model's input size\n",
    "\n",
    "train_gen = SiamesePairGenerator(X1_train, X2_train, y_train, batch_size=batch_size, img_size=img_size)\n",
    "val_gen = SiamesePairGenerator(X1_val, X2_val, y_val, batch_size=batch_size, img_size=img_size, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
